import os
import torch
import sounddevice as sd

# from TTS.api import TTS
from TTS.tts.models.glow_tts import GlowTTS
from TTS.tts.configs.glow_tts_config import GlowTTSConfig
from TTS.tts.utils.text.tokenizer import TTSTokenizer
from TTS.utils.audio import AudioProcessor

from transformers import SpeechT5HifiGan


# Get device
# device = "cuda" if torch.cuda.is_available() else "cpu"

# List available ğŸ¸TTS models
# print(TTS().list_models())

# Microsoft HiFi-GAN vocoder ì´ˆê¸°í™”
vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
base_path = os.path.dirname(os.path.abspath(__file__))
glowtts_model_path = os.path.join(base_path, "model/glowtts_model.pth")
glowtts_config_path = os.path.join(base_path, "model/glowtts_config.json")


# Glow-TTS ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
def load_glowtts(model_path, config_path):
    config = GlowTTSConfig()
    config.load_json(config_path)
    
    ap = AudioProcessor.init_from_config(config)
    tokenizer, config = TTSTokenizer.init_from_config(config)

    model = GlowTTS(config, ap, tokenizer)
    model.load_state_dict(torch.load(model_path, map_location="cpu", weights_only=True))
    model.eval()
    return model, tokenizer

# def load_glowtts_model():
#     config = GlowTTSConfig()
#     config.load_json(file_name=glowtts_config_path)
#     ap = AudioProcessor.init_from_config(config)
    
#     # Tokenizer ì´ˆê¸°í™”
#     tokenizer, config = TTSTokenizer.init_from_config(config)

#     model = GlowTTS(config, ap)
#     model.load_state_dict(torch.load(glowtts_model_path, map_location="cpu", weights_only=True))
#     model.eval()
#     return model, ap, tokenizer


# í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def synthesize_speech(text):
    # Glow-TTS ëª¨ë¸ ë° ì„¤ì • ë¡œë“œ
    glowtts_model, tokenizer = load_glowtts(glowtts_model_path, glowtts_config_path)
    print(glowtts_model.embedded_speaker_dim)

    # 1. í…ìŠ¤íŠ¸ë¥¼ í† í°í™” ë° ìŒì†Œí™”
    text_sequence = tokenizer.encode(text)
    text_tensor = torch.tensor([text_sequence], dtype=torch.long)
    text_lengths = torch.tensor([text_tensor.size(1)], dtype=torch.long)

    print(text_tensor.shape)
    print(text_lengths)

    # 2. Glow-TTSë¥¼ ì‚¬ìš©í•˜ì—¬ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±
    with torch.no_grad():
        mel_outputs = glowtts_model.inference(x=text_tensor)
    print('mel_outputs:', mel_outputs)

    # 3. HiFi-GAN vocoderë¥¼ ì‚¬ìš©í•˜ì—¬ wav ë³€í™˜
    with torch.no_grad():
        wav = vocoder(mel_outputs)

    print(wav)
    return wav


def make_tts_file(answer):
    # tts.voice_conversion_to_file(source_wav="tts/data/wavs/bae_korean2.wav", target_wav="tts/data/wavs/product_explain_bae.wav", file_path="output.wav")
    
    # tts.tts(
    #     text=answer,
    #     speaker_wav=wav_file_path,
    #     language="ko",
    #     file_path=output_file_path,
    #     speed=2.0
    # )
    return tts.tts(
        text=answer,
        speaker_wav=wav_file_path,
        language="ko",
        speed=2.0,
    )


# í…ìŠ¤íŠ¸ë¥¼ ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ìœ¼ë¡œ ë³€í™˜í•˜ê³  ìŒì„± ì‹ í˜¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
# def synthesize_speech(text):
#     # GlowTTS ëª¨ë¸, AudioProcessor, Tokenizer ë¡œë“œ
#     model, ap, tokenizer = load_glowtts_model()

#     # í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì €ë¡œ ì²˜ë¦¬
#     tokens = tokenizer.text_to_ids(text)
#     tokens = torch.LongTensor(tokens).unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
#     print("Tokens shape:", tokens.shape)
#     print("First token length:", len(tokens[0]))

#     # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ìƒì„±
#     with torch.no_grad():
#         outputs = model.inference(tokens)
#         print(outputs)
#         print("GlowTTS inference completed successfully.")
#         mel_post = outputs["mel_post"]  # ë©œ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ê°€ì ¸ì˜¤ê¸°
#         print("Mel spectrogram shape:", mel_post.shape)

#     try:
#         # SpeechT5 HiFi-GANì„ ì‚¬ìš©í•´ ìŒì„± ì‹ í˜¸ë¡œ ë³€í™˜
#         with torch.no_grad():
#             wav = vocoder(mel_post)
#             print("Vocoder synthesis completed successfully.")
#     except Exception as e:
#         print(f"Error during vocoder synthesis: {e}")
#         return None, None

#     return wav.cpu().numpy(), ap.sample_rate


def play_audio(audio, sample_rate=22050):
    # sample_rate = tts.synthesizer.output_sample_rate
    sd.play(audio, samplerate=sample_rate)
    sd.wait()

